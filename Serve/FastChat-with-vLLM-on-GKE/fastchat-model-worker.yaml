apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-worker-l4
spec:
  replicas: 1
  selector:
    matchLabels:
      app: model-worker-l4
  template:
    metadata:
      labels:
        app: model-worker-l4
    spec:
      containers:
      - image: us-central1-docker.pkg.dev/becky-daily-test-project/artifact-vllm/vllm-server:fastchat
        name: model-worker-l4
        command:
          - python3
          - -m
          - fastchat.serve.model_worker
          - --model-path
          - /gcs-mount/llama-2-7b-chat-hf
          - --host
          - "0.0.0.0"
          - --controller 
          - http://controller-svc:21001
          - --worker-address 
          - http://model-worker-l4-svc:21002
        ports:
        - containerPort: 21002
        resources:
          requests:
            nvidia.com/gpu: 1
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
        - name: gcs-fuse-csi-ephemeral
          mountPath: /gcs-mount
      serviceAccountName: vllm-l4
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 48G
      - name: gcs-fuse-csi-ephemeral
        csi:
          driver: gcsfuse.csi.storage.gke.io
          volumeAttributes:
            bucketName: ${BUCKET_NAME}
            mountOptions: "implicit-dirs"
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-l4

---
apiVersion: v1
kind: Service
metadata:
  name: model-worker-l4-svc
spec:
  ports:
  - port: 21002
    protocol: TCP
    targetPort: 21002
  selector:
    app: model-worker-l4
  type: ClusterIP